{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc0408bd-5e61-4827-96ab-d19040aadd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. What are the main tasks that autoencoders are used for?\n",
    "\n",
    "# Ans:\n",
    "# Autoencoders are commonly used for tasks such as data compression, feature extraction, denoising, anomaly detection,\n",
    "# and generative modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30671817-015f-4bef-989d-884d500e414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Suppose you want to train a classifier, and you have plenty of unlabeled training data but\n",
    "# only a few thousand labeled instances. How can autoencoders help? How would you proceed?\n",
    "\n",
    "# Ans:\n",
    "# Autoencoders can help in this scenario by pretraining a deep neural network on the unlabeled data to learn meaningful representations \n",
    "# of the input. These pretrained autoencoder weights can then be used as initialization for the classifier, which can be\n",
    "# fine-tuned using the labeled instances. This approach leverages the unsupervised learning capability of autoencoders to \n",
    "# improve the performance of the classifier with limited labeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e289061-c859-4992-8e04-419f0866fc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. If an autoencoder perfectly reconstructs the inputs, is it necessarily a good autoencoder?\n",
    "# How can you evaluate the performance of an autoencoder?\n",
    "\n",
    "# Ans:\n",
    "# No, perfect reconstruction alone does not necessarily make an autoencoder good. To evaluate the performance of an autoencoder, \n",
    "# you can consider other factors such as the loss function, reconstruction error, and the ability of the autoencoder to generalize \n",
    "# to unseen data. Additionally, qualitative assessment of the reconstructed outputs and the learned latent representations\n",
    "# can provide insights into the effectiveness of the autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0a0c26c-e45f-434d-9607-4743d2b68763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. What are undercomplete and overcomplete autoencoders? What is the main risk of an\n",
    "# excessively undercomplete autoencoder? What about the main risk of an overcomplete autoencoder?\n",
    "\n",
    "# Ans:\n",
    "# Undercomplete autoencoders have a smaller dimension in the bottleneck layer compared to the input layer.\n",
    "# The main risk is that they may lose important information during the compression process.\n",
    "# Overcomplete autoencoders have a larger dimension in the bottleneck layer compared to the input layer. The main risk is that they may \n",
    "# memorize the training data instead of learning meaningful representations, leading to poor generalization to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02588025-2d1d-404f-83e3-ae1be7b7a3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. How do you tie weights in a stacked autoencoder? What is the point of doing so?\n",
    "\n",
    "# Ans:\n",
    "# Tying weights in a stacked autoencoder involves setting the weights of the decoding layers to be the transpose of the weights \n",
    "# of the corresponding encoding layers. This reduces the number of parameters in the model and encourages the autoencoder to \n",
    "# learn more meaningful and efficient representations of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03dafa90-5960-4477-8546-880131040d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. What is a generative model? Can you name a type of generative autoencoder?\n",
    "\n",
    "# Ans:\n",
    "# A generative model is a type of model that can generate new samples that resemble the training data distribution. \n",
    "# One type of generative autoencoder is the Variational Autoencoder (VAE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c031c305-9d7f-4437-b863-76710733d99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. What is a GAN? Can you name a few tasks where GANs can shine?\n",
    "\n",
    "# Ans:\n",
    "# A GAN (Generative Adversarial Network) is a type of generative model that consists of two neural networks: a generator and a \n",
    "# discriminator. The generator generates new samples, while the discriminator tries to distinguish between real and generated samples.\n",
    "# GANs can excel in tasks such as image synthesis, image-to-image translation, and generating realistic and high-quality samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e5044ee-2629-4137-850c-f649849e78f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. What are the main difficulties when training GANs?\n",
    "\n",
    "# Ans:\n",
    "# The main difficulties when training GANs include mode collapse (where the generator fails to generate diverse samples),\n",
    "# training instability (difficulty in finding a stable equilibrium between the generator and discriminator), and the challenge\n",
    "# of finding the right balance between the generator and discriminator architectures and training dynamics. Additionally, GANs are\n",
    "# sensitive to hyperparameter settings and may require careful tuning for optimal performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ea69a7-d1fe-4153-94f6-f63b98f3c22d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
