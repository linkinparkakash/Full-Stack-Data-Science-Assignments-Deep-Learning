{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dff20f8e-1a7e-4e10-be8b-98fb8f5949ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. What are the advantages of a CNN over a fully connected DNN for image classification?\n",
    "\n",
    "# Ans:\n",
    "# Localized feature learning: CNNs leverage convolutional layers to learn spatially localized features, capturing patterns in \n",
    "# different regions of the image. This is particularly effective for image analysis tasks where spatial relationships are important.\n",
    "\n",
    "# Parameter efficiency: CNNs use parameter sharing and local connectivity, significantly reducing the number of parameters compared to\n",
    "# fully connected DNNs. This makes CNNs more efficient for processing high-dimensional image data.\n",
    "\n",
    "# Translation invariance: CNNs are able to recognize patterns regardless of their position in the image, thanks to pooling layers that \n",
    "# downsample feature maps. This enables CNNs to handle variations in object position and scale.\n",
    "\n",
    "# Hierarchical feature representation: CNNs typically consist of multiple convolutional and pooling layers, allowing them to learn \n",
    "# hierarchical representations of image features. This enables the network to capture increasingly complex and abstract features.\n",
    "\n",
    "# Overall, CNNs excel in image classification tasks due to their ability to capture spatial information, parameter efficiency, \n",
    "# translation invariance, and hierarchical feature learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e86106f9-257b-4161-8fcc-1e5909d57f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Consider a CNN composed of three convolutional layers, each with 3 × 3 kernels, a stride of\n",
    "# 2, and &quot;same&quot; padding. The lowest layer outputs 100 feature maps, the middle one outputs\n",
    "# 200, and the top one outputs 400. The input images are RGB images of 200 × 300 pixels.\n",
    "\n",
    "# Ans:\n",
    "# The CNN described consists of three convolutional layers with 3x3 kernels, a stride of 2, and \"same\" padding. The lowest layer produces\n",
    "# 100 feature maps, the middle layer produces 200, and the top layer produces 400. The input images are RGB images with dimensions of \n",
    "# 200x300 pixels.\n",
    "# To calculate the total number of parameters in the CNN, we need to consider the parameters in the convolutional layers.\n",
    "\n",
    "# For each convolutional layer, the number of parameters can be calculated as:\n",
    "# (number of input channels * kernel size * kernel size * number of output channels) + (number of output channels)\n",
    "\n",
    "# For the given CNN with three convolutional layers, each with 3x3 kernels, the parameter calculation would be as follows:\n",
    "\n",
    "# First Convolutional Layer:\n",
    "# Parameters = (3 * 3 * 3 * 100) + 100 = 2,800\n",
    "\n",
    "# Second Convolutional Layer:\n",
    "# Parameters = (100 * 3 * 3 * 200) + 200 = 1,802,00\n",
    "\n",
    "# Third Convolutional Layer:\n",
    "# Parameters = (200 * 3 * 3 * 400) + 400 = 7,204,00\n",
    "\n",
    "# Total number of parameters = 2,800 + 1,802,00 + 7,204,00 = 9,007,200\n",
    "\n",
    "# Now, to estimate the RAM required for predictions and training:\n",
    "\n",
    "# For a single prediction instance:\n",
    "# Assuming a 32-bit float (4 bytes) for each parameter, the RAM required for predictions would be:\n",
    "# RAM = Total number of parameters * 4 bytes = 9,007,200 * 4 = 36,028,800 bytes (approximately 34.35 MB)\n",
    "\n",
    "# For a mini-batch of 50 images:\n",
    "# The RAM required would be:\n",
    "# RAM = Total number of parameters * mini-batch size * 4 bytes = 9,007,200 * 50 * 4 = 1,801,440,000 bytes (approximately 1.68 GB)\n",
    "\n",
    "# Please note that these calculations consider only the parameters and not the memory required for storing intermediate activations, \n",
    "# gradients, or other overheads associated with training the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c647da62-9b36-432a-bd02-e792988e56c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. If your GPU runs out of memory while training a CNN, what are five things you could try to solve the problem?\n",
    "\n",
    "# Ans:\n",
    "# If your GPU runs out of memory while training a CNN, here are five things you could try to solve the problem:\n",
    "\n",
    "# Reduce batch size: Use a smaller batch size to reduce the memory requirements per iteration.\n",
    "# Decrease model complexity: Reduce the number of layers, parameters, or filter sizes in the CNN architecture to reduce memory usage.\n",
    "# Use mixed precision training: Utilize mixed precision techniques, such as TensorFlow's Automatic Mixed Precision (AMP), to reduce memory\n",
    "# usage without sacrificing accuracy.\n",
    "# Enable memory optimization techniques: Enable memory optimization flags and settings provided by deep learning frameworks, such as \n",
    "# TensorFlow's memory growth or memory optimization options.\n",
    "# Utilize data augmentation: Apply data augmentation techniques during training to generate augmented images on-the-fly, reducing the\n",
    "# need to store additional copies of the training data in memory.\n",
    "# These approaches can help mitigate memory issues when training a CNN on a GPU, allowing for successful training even with limited \n",
    "# GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f821b3c-6083-40af-9771-0783401b3a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Why would you want to add a max pooling layer rather than a convolutional layer with the same stride?\n",
    "\n",
    "# Ans:\n",
    "# Adding a max pooling layer instead of a convolutional layer with the same stride can be beneficial for two reasons:\n",
    "\n",
    "# Dimension reduction: Max pooling reduces the spatial dimensions of the feature maps by selecting the maximum value within each pooling \n",
    "# window. This helps in reducing the computational complexity and the number of parameters in the network.\n",
    "\n",
    "# Translation invariance: Max pooling introduces a degree of translation invariance by selecting the maximum value within each pooling \n",
    "# window. This allows the network to capture the presence of a feature regardless of its precise location in the input, making the\n",
    "# model more robust to variations in object position or spatial shifts.\n",
    "\n",
    "# Overall, using a max pooling layer provides dimension reduction and translation invariance, which can enhance the network's efficiency\n",
    "# and robustness in handling spatial features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0a9788d-9388-4af3-bc74-f0e4913cef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. When would you want to add a local response normalization layer?\n",
    "\n",
    "# Ans:\n",
    "# A local response normalization (LRN) layer is typically added in convolutional neural networks (CNNs) when there is a need to enhance\n",
    "# the network's ability to generalize across different contrast levels and suppress response to strong activations. The LRN layer helps\n",
    "# normalize the response of neurons within a local neighborhood, allowing the network to focus on relatively stronger activations and \n",
    "# promote competition among neighboring neurons. This can be beneficial in scenarios where contrast normalization and local inhibition\n",
    "# are desired, such as in image recognition tasks where variations in contrast and response suppression are relevant factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "270b9ccd-88b9-49b5-8b2a-709644e3fb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Can you name the main innovations in AlexNet, compared to LeNet-5? What about the main innovations in GoogLeNet, ResNet, SENet,\n",
    "# and Xception?\n",
    "\n",
    "# Ans:\n",
    "# AlexNet introduced several key innovations compared to LeNet-5, including the use of rectified linear units (ReLU) as activation \n",
    "# functions, dropout regularization, data augmentation, and the utilization of GPUs for efficient training of deep neural networks.\n",
    "\n",
    "# GoogLeNet introduced the inception module, which utilized parallel convolutional layers of different sizes to capture features at \n",
    "# various scales and combined them through concatenation. This allowed for efficient and deep network architectures.\n",
    "\n",
    "# ResNet introduced residual connections, which enabled the training of extremely deep networks by addressing the vanishing gradient \n",
    "# problem. These skip connections allowed gradients to flow directly to earlier layers, facilitating the training of deep neural \n",
    "# networks with hundreds or even thousands of layers.\n",
    "\n",
    "# SENet introduced the concept of squeeze-and-excitation blocks, which adaptively recalibrate the channel-wise feature responses by \n",
    "# leveraging global information. This mechanism improves the model's ability to capture important features and enhances its performance.\n",
    "\n",
    "# Xception introduced depthwise separable convolutions, which decouple spatial and channel-wise convolutions. This reduces the \n",
    "# computational complexity while maintaining the representational capacity, resulting in more efficient and powerful network architectures.\n",
    "\n",
    "# These innovations in deep learning architectures have played significant roles in advancing the field and achieving state-of-the-art \n",
    "# performance in various computer vision tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbe710a9-23aa-414f-87bf-43e50e5831c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. What is a fully convolutional network? How can you convert a dense layer into a convolutional layer?\n",
    "\n",
    "# Ans:\n",
    "# A fully convolutional network (FCN) is a type of neural network architecture that consists entirely of convolutional layers, \n",
    "# without any fully connected (dense) layers. FCNs are commonly used in tasks such as image segmentation, where the output is a\n",
    "# dense prediction map.\n",
    "\n",
    "# To convert a dense layer into a convolutional layer, you can use a 1x1 convolutional layer. This operation allows for spatial \n",
    "# information to be preserved while transforming the dense layer into a convolutional layer. By setting the appropriate number \n",
    "# of filters in the 1x1 convolutional layer, you can control the output dimensions and effectively convert the dense layer into a \n",
    "# convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae30a5de-1409-4fab-8387-9ed1431cc46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. What is the main technical difficulty of semantic segmentation?\n",
    "\n",
    "# Ans:\n",
    "# The main technical difficulty of semantic segmentation is accurately assigning the correct class label to each pixel in an image.\n",
    "# This requires overcoming challenges such as handling object boundaries, handling varying object sizes and shapes, \n",
    "# dealing with occlusions and overlapping objects, and ensuring spatial coherence in the segmentation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c51fba7-9616-467a-9ce7-d63fd6f5d55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard<2.13,>=2.12\n",
      "  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (65.5.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.0-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<1.24,>=1.22 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.23.4)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting keras<2.13,>=2.12.0\n",
      "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.32.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.54.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.13,>=2.12.0\n",
      "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.5.9-py2.py3-none-any.whl (26 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting wrapt<1.15,>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
      "Collecting jax>=0.3.15\n",
      "  Downloading jax-0.4.10.tar.gz (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.21.8)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow) (1.9.3)\n",
      "Collecting ml-dtypes>=0.1.0\n",
      "  Downloading ml_dtypes-0.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (190 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.18.0-py2.py3-none-any.whl (178 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.9/178.9 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.3.4-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.28.1)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (1.26.11)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.1)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
      "Building wheels for collected packages: jax\n",
      "  Building wheel for jax (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jax: filename=jax-0.4.10-py3-none-any.whl size=1480503 sha256=4406acef48d09f40ea76f2a658e7399b5c49cc6a77a16bbfe2076a5cd157fb85\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/f8/55/5b/9dde9a2af48db48d64b8cc3877f0670cf11c5d78de392c3f05\n",
      "Successfully built jax\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, opt-einsum, ml-dtypes, markdown, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, rsa, requests-oauthlib, pyasn1-modules, jax, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 flatbuffers-23.5.9 gast-0.4.0 google-auth-2.18.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.54.2 jax-0.4.10 keras-2.12.0 libclang-16.0.0 markdown-3.4.3 ml-dtypes-0.1.0 opt-einsum-3.3.0 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.12.3 tensorboard-data-server-0.7.0 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-io-gcs-filesystem-0.32.0 termcolor-2.3.0 werkzeug-2.3.4 wrapt-1.14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aef6661d-1b02-455f-b8c0-7a09007508f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 233s 62ms/step - loss: 0.1234 - accuracy: 0.9628\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 229s 61ms/step - loss: 0.0440 - accuracy: 0.9861\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 233s 62ms/step - loss: 0.0310 - accuracy: 0.9903\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 229s 61ms/step - loss: 0.0221 - accuracy: 0.9932\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 231s 62ms/step - loss: 0.0173 - accuracy: 0.9946\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 235s 63ms/step - loss: 0.0126 - accuracy: 0.9958\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 235s 63ms/step - loss: 0.0114 - accuracy: 0.9963\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 232s 62ms/step - loss: 0.0104 - accuracy: 0.9964\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 234s 62ms/step - loss: 0.0081 - accuracy: 0.9972\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 240s 64ms/step - loss: 0.0085 - accuracy: 0.9972\n",
      "313/313 [==============================] - 13s 41ms/step - loss: 0.0509 - accuracy: 0.9890\n",
      "Test accuracy: 0.9890000224113464\n"
     ]
    }
   ],
   "source": [
    "# 9. Build your own CNN from scratch and try to achieve the highest possible accuracy on MNIST.\n",
    "\n",
    "# Sol:\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape(-1, 28, 28, 1) / 255.0\n",
    "test_images = test_images.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f0c46f5-0acb-4a92-b1f5-508ebba2e4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1688/1688 [==============================] - 97s 57ms/step - loss: 0.1519 - accuracy: 0.9542 - val_loss: 0.0582 - val_accuracy: 0.9820\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 91s 54ms/step - loss: 0.0529 - accuracy: 0.9836 - val_loss: 0.0493 - val_accuracy: 0.9867\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 88s 52ms/step - loss: 0.0328 - accuracy: 0.9892 - val_loss: 0.0563 - val_accuracy: 0.9857\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 88s 52ms/step - loss: 0.0216 - accuracy: 0.9929 - val_loss: 0.0565 - val_accuracy: 0.9852\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 88s 52ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.0695 - val_accuracy: 0.9810\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 91s 54ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.0538 - val_accuracy: 0.9885\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 89s 53ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.0478 - val_accuracy: 0.9892\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 92s 54ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.0598 - val_accuracy: 0.9883\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 89s 53ms/step - loss: 0.0061 - accuracy: 0.9978 - val_loss: 0.0566 - val_accuracy: 0.9892\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 88s 52ms/step - loss: 0.0047 - accuracy: 0.9983 - val_loss: 0.0623 - val_accuracy: 0.9877\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.0607 - accuracy: 0.9851\n",
      "Test accuracy: 0.9850999712944031\n"
     ]
    }
   ],
   "source": [
    "# 10. Use transfer learning for large image classification, going through these steps:\n",
    "# a. Create a training set containing at least 100 images per class. For example, you could\n",
    "# classify your own pictures based on the location (beach, mountain, city, etc.), or\n",
    "# alternatively you can use an existing dataset (e.g., from TensorFlow Datasets).\n",
    "# b. Split it into a training set, a validation set, and a test set.\n",
    "# c. Build the input pipeline, including the appropriate preprocessing operations, and optionally add data augmentation.\n",
    "# d. Fine-tune a pretrained model on this dataset.\n",
    "\n",
    "# Sol:\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "\n",
    "# Convert labels to one-hot encoded vectors\n",
    "y_train = tf.one_hot(y_train, depth=10)\n",
    "y_test = tf.one_hot(y_test, depth=10)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train,\n",
    "          validation_split=0.1,\n",
    "          batch_size=32,\n",
    "          epochs=10)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63e8669-b154-4d12-b0f3-b4c6145f10ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
